{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import DenseNet121  # Changed to DenseNet121 for better medical image analysis\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 16  # Smaller batch size for better generalization\n",
    "EPOCHS = 100     # More epochs for thorough training\n",
    "BASE_PATH = \"D:/LALA/chest_xray\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_generators():\n",
    "    \"\"\"Create data generators with medical-specific augmentation\"\"\"\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=10,        # Limited rotation for medical images\n",
    "        width_shift_range=0.1,    # Subtle shifts\n",
    "        height_shift_range=0.1,\n",
    "        zoom_range=0.1,          # Subtle zoom\n",
    "        horizontal_flip=True,     # Only horizontal flip is medically valid\n",
    "        fill_mode='constant',\n",
    "        validation_split=0.1,\n",
    "        brightness_range=[0.9, 1.1]  # Subtle brightness adjustment\n",
    "    )\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    print(\"Creating generators...\")\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        os.path.join(BASE_PATH, 'train'),\n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        classes=['Not Infected', 'Infected'],\n",
    "        shuffle=True,\n",
    "        subset='training'\n",
    "    )\n",
    "\n",
    "    validation_generator = train_datagen.flow_from_directory(\n",
    "        os.path.join(BASE_PATH, 'train'),\n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='binary',\n",
    "        classes=['Not Infected', 'Infected'],\n",
    "        shuffle=True,\n",
    "        subset='validation'\n",
    "    )\n",
    "\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        os.path.join(BASE_PATH, 'test'),\n",
    "        target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        batch_size=1,  # Batch size 1 for precise evaluation\n",
    "        class_mode='binary',\n",
    "        classes=['Not Infected', 'Infected'],\n",
    "        shuffle=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Create the model\n",
    "def create_model():\n",
    "    # Load the pre-trained EfficientNetB0 model\n",
    "    base_model = EfficientNetB0(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "    )\n",
    "    \n",
    "    # Freeze the base model layers\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        GlobalAveragePooling2D(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Calculate class weights\n",
    "def calculate_class_weights(train_generator):\n",
    "    total_samples = train_generator.samples\n",
    "    n_samples_per_class = train_generator.class_counts\n",
    "    n_classes = len(n_samples_per_class)\n",
    "    \n",
    "    class_weights = {}\n",
    "    for i in range(n_classes):\n",
    "        class_weights[i] = total_samples / (n_classes * n_samples_per_class[i])\n",
    "    \n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. Training function\n",
    "def train_model():\n",
    "    # Create generators\n",
    "    train_generator, validation_generator, test_generator = create_data_generators()\n",
    "    \n",
    "    # Create model\n",
    "    model = create_model()\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-4),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC()]\n",
    "    )\n",
    "    \n",
    "    # Set up callbacks\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=8,\n",
    "            restore_best_weights=True,\n",
    "            min_delta=0.001\n",
    "        ),\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=4,\n",
    "            min_lr=1e-7\n",
    "        ),\n",
    "        ModelCheckpoint(\n",
    "            'best_model.h5',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            mode='max'\n",
    "        )\n",
    "    ]\n",
    "     # Calculate class weights\n",
    "    class_weights = calculate_class_weights(train_generator)\n",
    "    \n",
    "    # Initial training\n",
    "    print(\"Initial training...\")\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=callbacks,\n",
    "        class_weight=class_weights\n",
    "    )\n",
    "    \n",
    "    # Fine-tuning\n",
    "    print(\"Fine-tuning...\")\n",
    "    base_model = model.layers[0]\n",
    "    base_model.trainable = True\n",
    "    \n",
    "    # Freeze early layers\n",
    "    for layer in base_model.layers[:-30]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Recompile with lower learning rate\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-6),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(), tf.keras.metrics.AUC()]\n",
    "    )\n",
    "    \n",
    "    # Continue training\n",
    "    history_fine = model.fit(\n",
    "        train_generator,\n",
    "        epochs=20,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=callbacks,\n",
    "        class_weight=class_weights\n",
    "    )\n",
    "    # Evaluate on test set\n",
    "    test_results = model.evaluate(test_generator)\n",
    "    print(\"\\nTest results:\")\n",
    "    for metric_name, value in zip(model.metrics_names, test_results):\n",
    "        print(f\"{metric_name}: {value:.4f}\")\n",
    "    \n",
    "    # Save the final model\n",
    "    model.save('final_model.h5')\n",
    "    return model, history, history_fine\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Plot training history\n",
    "def plot_training_history(history, history_fine):\n",
    "    def plot_metric(metric):\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        \n",
    "        # Initial training\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history[metric])\n",
    "        plt.plot(history.history[f'val_{metric}'])\n",
    "        plt.title(f'Initial Training - {metric}')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(metric)\n",
    "        plt.legend(['Train', 'Validation'])\n",
    "        \n",
    "        # Fine-tuning\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history_fine.history[metric])\n",
    "        plt.plot(history_fine.history[f'val_{metric}'])\n",
    "        plt.title(f'Fine-tuning - {metric}')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel(metric)\n",
    "        plt.legend(['Train', 'Validation'])\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Plot accuracy and loss\n",
    "    plot_metric('accuracy')\n",
    "    plot_metric('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class distribution: {'Infected': 3895, 'Not Infected': 1341}\n",
      "Validation class distribution: {'Infected': 8, 'Not Infected': 8}\n",
      "Test class distribution: {'Infected': 390, 'Not Infected': 234}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "def count_images_in_classes(folder_path):\n",
    "    class_counts = {}\n",
    "    for class_name in os.listdir(folder_path):\n",
    "        class_path = os.path.join(folder_path, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            class_counts[class_name] = len(os.listdir(class_path))\n",
    "    return class_counts\n",
    "\n",
    "train_counts = count_images_in_classes('D:/LALA/chest_xray/train')\n",
    "val_counts = count_images_in_classes('D:/LALA/chest_xray/val')\n",
    "test_counts = count_images_in_classes('D:/LALA/chest_xray/test')\n",
    "\n",
    "print(\"Train class distribution:\", train_counts)\n",
    "print(\"Validation class distribution:\", val_counts)\n",
    "print(\"Test class distribution:\", test_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
